#%autoreload 2

#%matplotlib inline

import math
import time
import os
import glob
import numpy as np
import matplotlib.pyplot as plt
import csv
from tqdm import tqdm
from PIL import Image
from sklearn.metrics import confusion_matrix
from torchsummary import summary
from torch.autograd import Variable

np.set_printoptions(precision=2)
np.random.seed(1234)


import torch
import torch.nn as nn
import torch.optim as optim
from torch.autograd import Variable
import torch.utils.data.sampler as sampler

use_gpu = torch.cuda.is_available()

import torchvision
import torchvision.datasets as dataset
import torchvision.models as models
import torchvision.transforms as transforms

from google.colab import drive
drive.mount('/drive')

# Hyper parameters
Data_DIR = "/drive/My Drive/cat-dog/"
Image_size = 224 # size of each img
batch_size = 256 # 25 ta ax midam vase train

os.listdir(Data_DIR)



trn_dir = f'{Data_DIR}trainset'  #make string my train dataset
tst_dir = f'{Data_DIR}testset'   # make string my validation dataset


print(os.listdir(trn_dir))
print(os.listdir(tst_dir))

# use glob library to address my img
trn_fname = glob.glob(f'{trn_dir}/*/*.jpg')  # use glob to see where is my trainset and I mentioned which files I want!!!
trn_fname[:5]

img = plt.imread(trn_fname[1])
plt.imshow(img)

#Data processing
# resize the image to uniqe one and transfor it to tensor
tfms = transforms.Compose([
    transforms.Resize((Image_size, Image_size)), 
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(), # Tensor or matrix
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # RGB ,normlzie all imgs,to use in my mean and sd
])

#Apply transformation
train_ds = dataset.ImageFolder(trn_dir, transform=tfms)
test_ds = dataset.ImageFolder(tst_dir, transform=tfms)
train_ds.class_to_idx

#Split data into training and validation
TRAIN_SIZE = int(len(train_ds.imgs) *0.8)
VALID_SIZE = len(train_ds.imgs) - TRAIN_SIZE

indices = list(range(len(train_ds.imgs)))
np.random.seed(123)
np.random.shuffle(indices)

train_idx, valid_idx = indices[:TRAIN_SIZE], indices[TRAIN_SIZE:]

train_sampler = sampler.SubsetRandomSampler(train_idx)
valid_sampler = sampler.SubsetRandomSampler(valid_idx)

train_dl = torch.utils.data.DataLoader(
    train_ds, batch_size=batch_size, sampler=train_sampler, num_workers=8)

valid_dl = torch.utils.data.DataLoader(
    train_ds, batch_size=batch_size,  sampler=valid_sampler, num_workers=8)

test_dl = torch.utils.data.DataLoader(
    test_ds, batch_size=batch_size,num_workers=8)

print("Summary:")
print('Size train Dataset:',len(train_dl)*batch_size)
print('Size validation:',len(valid_dl)*batch_size)
print('Test images:',len(test_ds))
print('Image size:', train_ds[0][0].size())


inputs, targets = next(iter(train_dl)) # there is an object (train_dl) that we can make itration, it take 16 imgs
out = torchvision.utils.make_grid(inputs, padding=3) # khoshgel bechinam beside eachother LOL

plt.figure(figsize=(16, 12));

def imshow(inp, title=None):
    """Imshow for Tensor.
    """
    inp = inp.numpy().transpose((1, 2, 0))
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    inp = std * inp + mean
    inp = np.clip(inp, 0, 1)
    plt.imshow(inp)
    plt.axis('off')
    if title is not None:
        plt.title(title)

imshow(out, title='Random images from training data')

# class VGG(nn.Module):
    
#     def __init__(self): # __init__ is constructor 
#         super(VGG, self).__init__()
        
#         self.layer1 = nn.Sequential(
#             nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(3, 3),
#             stride=1, padding=1),
#             nn.ReLU(),
#             nn.MaxPool2d(2, stride=2)
#         )

#         self.layer2 = nn.Sequential(
#             nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3),
#             stride=1, padding=1),
#             nn.ReLU(),
#             nn.MaxPool2d(2, stride=2)
#         )
        
#         self.layer3 = nn.Sequential(
#             nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3, 3),
#             stride=1, padding=1),
#             nn.ReLU(),
#             nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3, 3),
#             stride=1, padding=1),
#             nn.ReLU(),
#             nn.MaxPool2d(2, stride=2)
#         )
        
#         self.layer4 = nn.Sequential(
#             nn.Conv2d(in_channels=256, out_channels=512, kernel_size=(3, 3),
#             stride=1, padding=1),
#             nn.ReLU(),
#             nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3, 3),
#             stride=1, padding=1),
#             nn.ReLU(),
#             nn.MaxPool2d(2, stride=2)
#         )
        
#         self.layer5 = nn.Sequential(
#             nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3, 3),
#             stride=1, padding=1),
#             nn.ReLU(),
#             nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3, 3),
#             stride=1, padding=1),
#             nn.ReLU(),
#             nn.MaxPool2d(2, stride=2)
#         )
        
        
#         self.fc = nn.Sequential(
#             nn.Linear(512*7*7, 4096),
#             nn.ReLU(),
#             nn.Linear(4096, 4096),
#             nn.ReLU(),
#             nn.Linear(4096, 1000),
#             nn.ReLU(),
#             nn.Linear(1000, 2),
#             nn.Softmax()
#         )
        
#     def forward(self, x):
#         out = self.layer1(x)
#         out = self.layer2(out)            
#         out = self.layer3(out)
#         out = self.layer4(out)
#         out = self.layer5(out)
#         out = out.view(out.size(0), -1) 
#         out = self.fc(out)
        
#         return out

class SimpleCNN(nn.Module):
    
    def __init__(self): # __init__ is constructor 
        super(SimpleCNN, self).__init__()
        
        self.conv1 = nn.Sequential(
            nn.Conv2d(3, 16,  kernel_size=(3, 3),stride=1, padding=1), # 3 = RGB(3channal), 16= 16 filter, padding= reduce the sie 1 column and rows
            nn.ReLU(), # nonlinear AF, - make 0
            nn.MaxPool2d(2, stride=2)
        )
        
        self.conv2 = nn.Sequential(
            nn.Conv2d(16, 32,   kernel_size=(3, 3),stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, stride=2)
        )
        
        self.conv3 = nn.Sequential(
            nn.Conv2d(32, 64,  kernel_size=(3, 3),stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, stride=2)
        )
        
        self.fc =  nn.Sequential(
            nn.Linear(28 * 28 * 64, 500), # fully connected layer, in pytorch we call linear layer, make the all layer to 2 vector (0,1)
            nn.ReLU(),
            nn.Linear(500, 2),
            nn.Softmax()
        )
    def forward(self, x):
        out = self.conv1(x)
        out = self.conv2(out)             # (bs, C, H, W)
        out = self.conv3(out)
#         print(out.size())
        out = out.view(out.size(0), -1)  #(bs, C, H, W)
        out = self.fc(out)
        
        return out

cuda_available = torch.cuda.is_available()

#  run
model = SimpleCNN()
model.cuda()
summary(model, (3, 224,224))

if cuda_available:
    model = model.cuda()
#Loss function and 
criterion = nn.CrossEntropyLoss() # minimize this 
optimizer = optim.SGD(model.parameters(), lr=0.01) # stochastic gradien, W = W - lr * dW


def to_var(x):
    if torch.cuda.is_available():
        x = x.cuda()
    return Variable(x)

# for epoch in range(10):
#     losses = []
#     # Train
#     for batch_idx, (inputs, targets) in enumerate(train_dl):
#         if cuda_available:
#             inputs, targets = inputs.cuda(), targets.cuda()

#         optimizer.zero_grad()
#         inputs, targets = Variable(inputs), Variable(targets)
#         outputs = model(inputs)
#         loss = criterion(outputs, targets)
#         loss.backward()
#         optimizer.step()
#         losses.append(loss.item())

#     print('Epoch : %d Loss : %.3f ' % (epoch, np.mean(losses)))
    
#     # Evaluate
#     model.eval()
#     total = 0
#     correct = 0
#     for batch_idx, (inputs, targets) in enumerate(test_dl):
#         if cuda_available:
#             inputs, targets = inputs.cuda(), targets.cuda()

#         inputs, targets = Variable(inputs, volatile=True), Variable(targets, volatile=True)
#         outputs = model(inputs)
#         _, predicted = torch.max(outputs.data, 1)
#         total += targets.size(0)
#         correct += predicted.eq(targets.data).cpu().sum()

#     print('Epoch : %d Test Acc : %.3f' % (epoch, 100.*correct/total))
#     print('--------------------------------------------------------------')
#     model.train()

#Train
num_epochs = 50
losses = []
epoch_losses = []
for epoch in range(num_epochs):
    for i, (inputs, targets) in enumerate(train_dl):
        inputs = to_var(inputs)
        targets = to_var(targets)
                
        # forward
        optimizer.zero_grad()
        outputs = model(inputs)
        
        # loss
        loss = criterion(outputs, targets)
        losses += [loss.item()] # draw fig
        
        # loos backward
        loss.backward()
        
        #update params
        optimizer.step()
        
        #report
        print ('Epoch [%2d/%3d], Step [%3d/%3d], Loss: %.4f' 
                   % (epoch + 1, num_epochs, i + 1, len(train_ds) // batch_size, loss.item()))
    epoch_losses.append(np.mean(losses))

plt.figure(figsize=(12, 4))
plt.plot(epoch_losses)
plt.xlabel('iteration')
plt.ylabel('loss')
plt.title('Cross Entropy loss')

# def evaluate_model(model, DataLoader):
#     model.eval()  # for batch norm layer
correct = 0
total = 0
with torch.no_grad():
    for data in valid_dl:
        images, labels = data
        images = to_var(images)
        labels = to_var(labels)
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print('Accuracy of the network on the valid images: %d %%' % (100 * correct / total))

correct = 0
total = 0
with torch.no_grad():
    for data in train_dl:
        images, labels = data
        images = to_var(images)
        labels = to_var(labels)
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print('Accuracy of the network on the train images: %d %%' % (100 * correct / total))

correct = 0
total = 0
predictions = []
with torch.no_grad():
    for data in test_dl:
        images, labels = data
        images = to_var(images)
        labels = to_var(labels)
        outputs = model(images)
        predictions.append(outputs)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))

# Submit the results

def predictCSV(predicts, file_path):
  labels = {0:'Cat', 1:'Dog'}
  with open(file_path,'w',newline='') as csvfile:
    writer = csv.writer(csvfile, delimiter=',')
    writer.writerow(("id","label"))
    for i, label in enumerate(predicts):
#       _, predict = torch.max(predicts[i].data, 0)
#       print(int(predicts[i].data[0]))
      writer.writerow((i+1,labels[int(predicts[i].data[0])]))
#   debug("save predict csv files of model to :{}".format(file_path))

# print(predictions)
predictCSV(predictions,"kaggle.csv")


